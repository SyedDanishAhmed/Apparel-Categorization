{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# import skfuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'D:/Denim/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-4269c95792bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpredicted_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLUSTER_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-169-bfc24b28b7a2>\u001b[0m in \u001b[0;36mtransfer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpath_new\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"D:/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_new\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'D:/Denim/'"
     ]
    }
   ],
   "source": [
    "all_path=glob.glob(\"D:/Project/Train/*/*Train*\")\n",
    "\n",
    "# categories=get_categories(all_path)\n",
    "CLUSTER_SIZE=3\n",
    "paths=all_path\n",
    "categories_object=Categories(all_path)\n",
    "categories=categories_object.get_categories()\n",
    "categories = list(categories)\n",
    "for category in categories:\n",
    "    paths=glob.glob(\"D:/Project/Train\\\\\"+category+\"\\\\*Train*\")\n",
    "    image_array=create_image_np_array(paths)\n",
    "    model=Model(image_array,CLUSTER_SIZE)\n",
    "    kmeans=model.model_fitting()\n",
    "    predicted_array=model_predict(kmeans,image_array)\n",
    "    copy=Copy(CLUSTER_SIZE,predicted_array,paths,category)\n",
    "    copy.transfer()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categories:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    def get_categories(self):\n",
    "        categories=[]\n",
    "        for i in range(len(self.path)):\n",
    "            categories.append(self.path[i][findnth(self.path[i],\"\\\\\",1)+1:findnth(self.path[i],\"\\\\\",2)])\n",
    "\n",
    "        categories=set(categories)\n",
    "        return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sub_categories(Categories):\n",
    "    def __init__(self, path):\n",
    "        super().__init__(path)\n",
    "    def get_sub_categories(path):\n",
    "        sub_categories=[]\n",
    "        for i in range(len(self.path)):\n",
    "            sub_categories.append(self.path[i][findnth(self.path[i],\"\\\\\",2)+1:findnth(self.path[i],\"\\\\\",3)])\n",
    "\n",
    "        sub_categories=set(sub_categories)\n",
    "        return sub_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_array):\n",
    "    scale_percent = 60 # percent of original size\n",
    "    width = int(image_array.shape[1] * scale_percent / 100)\n",
    "    height = int(image_array.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized = cv2.resize(image_array, dim, interpolation = cv2.INTER_AREA) \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_image_np_array(paths):\n",
    "    images=[]\n",
    "    for path in paths:\n",
    "        original_image=misc.imread(path)\n",
    "        resized_image=resize_image(original_image)\n",
    "        images.append(resized_image.flatten().tolist())\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, image_array,cluster_size):\n",
    "        self.image_array=image_array\n",
    "        self.cluster_size=cluster_size\n",
    "    def model_fitting(self):\n",
    "        kmeans = KMeans(n_clusters=self.cluster_size, n_init=1000, random_state=0)\n",
    "        return kmeans.fit(self.image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(kmeans,image_array):\n",
    "    predicted_array=kmeans.predict(image_array)\n",
    "    return predicted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ to find the nth letter ###############\n",
    "def findnth(haystack, needle, n):\n",
    "    parts= haystack.split(needle, n)\n",
    "    if len(parts)<=n:\n",
    "        return -1\n",
    "    return len(haystack)-len(parts[-1])-len(needle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Copy:\n",
    "    def __init__(self, cluster_size,predicted_array,source,category):\n",
    "        self.cluster_size=cluster_size\n",
    "        self.predicted_array=predicted_array\n",
    "        self.source=source\n",
    "        self.category=category\n",
    "    def transfer(self):\n",
    "        path_new=\"D:/\"+self.category+\"/\"\n",
    "        os.mkdir(path_new)\n",
    "        for i in range(self.cluster_size):   \n",
    "            os.mkdir(path_new+str(i))\n",
    "        for i,j in enumerate(self.predicted_array):\n",
    "            src_file=self.source[i]\n",
    "            dest=path_new+str(j)\n",
    "            shutil.copy(src_file, dest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
